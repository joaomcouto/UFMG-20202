{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fourth-guidance",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/python3\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "from OpenGL.GLU import *\n",
    "from OpenGL import *\n",
    "from OpenGL.GLUT import *\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "from objloader import *\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import time\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#import OpenGL.GLU as glu\n",
    "#import OpenGL.GL as gl\n",
    "#import OpenGL.GLUT as glut\n",
    "#import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "overhead-slope",
   "metadata": {},
   "source": [
    "## 1. Calibração da Camera"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "existing-generic",
   "metadata": {},
   "source": [
    "Feita via \"Camera Calibration Toolbox for Matlab\" de Jean-Yves Bouguet (http://www.vision.caltech.edu/bouguetj/calib_doc/)\n",
    "\n",
    "Capturei frames 4 aleátorios do vídeo disponibilizado para fazer a calibração\n",
    "\n",
    "A seguir, os parametros obtidos e suas respectivas incertezas:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "brief-locking",
   "metadata": {},
   "source": [
    "Focal Length:          fc = [ 823.02785   857.55218 ] +/- [ 27.59011   25.29775 ]\n",
    "\n",
    "Principal point:       cc = [ 566.92369   396.42114 ] +/- [ 12.48074   22.10106 ]\n",
    "\n",
    "Skew:             alpha_c = [ 0.00000 ] +/- [ 0.00000  ]   => angle of pixel axes = 90.00000 +/- 0.00000 degrees\n",
    "\n",
    "Distortion:            kc = [ 0.09076   -0.21946   -0.00693   -0.00024  0.00000 ] +/- [ 0.07284   0.50725   0.00776   0.00641  0.00000 ]\n",
    "\n",
    "Pixel error:          err = [ 0.37915   0.42384 ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "configured-vegetation",
   "metadata": {},
   "source": [
    "Com essa saída definimos a matriz de parametros intrinsecos da câmera:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tropical-given",
   "metadata": {},
   "outputs": [],
   "source": [
    "intrinsicMatrix = np.array([\n",
    "                            [823.02785, 0.0, 320], \n",
    "                            [0.0, 857.55218, 240], \n",
    "                            [0.0, 0.0, 1.0]\n",
    "                            ])\n",
    "cameraDistortion = [ 0.09076, -0.21946 ,-0.00693 ,-0.00024, 0.00000 ] \n",
    "#print(intrinsicMatrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "breathing-quilt",
   "metadata": {},
   "outputs": [],
   "source": [
    "render_pikachu = True\n",
    "render_cubes = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "green-interaction",
   "metadata": {},
   "source": [
    "# 2. Determinando a posição e orientação do alvo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "celtic-rider",
   "metadata": {},
   "source": [
    "## 2.1 O Video"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "crucial-mapping",
   "metadata": {},
   "source": [
    "##### 2.1.1 leitura do vídeo de input via OpenCV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "instrumental-circular",
   "metadata": {},
   "source": [
    "Ref: https://theailearner.com/2018/10/15/extracting-and-saving-video-frames-using-opencv-python/\n",
    "\n",
    "Ref2: https://stackoverflow.com/questions/33311153/python-extracting-and-saving-video-frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "offensive-baseline",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputVideo = cv2.VideoCapture('entrada.mp4')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "angry-leeds",
   "metadata": {},
   "source": [
    "##### 2.1.2 Captura e decodificação de frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dietary-retro",
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = []\n",
    "#success, frame = inputVideo.read()\n",
    "success,image = inputVideo.read()\n",
    "while success:\n",
    "    frames.append(image)\n",
    "    success, image = inputVideo.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "detected-funds",
   "metadata": {},
   "source": [
    "## 2.2 - O alvo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "spatial-indonesian",
   "metadata": {},
   "source": [
    "##### 2.2.1 Leitura e binarização do alvo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pacific-reproduction",
   "metadata": {},
   "outputs": [],
   "source": [
    "alvo0rot = cv2.imread('alvo.jpg', 0)\n",
    "_, alvo0rot = cv2.threshold(alvo0rot, 127, 255, cv2.THRESH_BINARY)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rural-ridge",
   "metadata": {},
   "source": [
    "##### 2.2.2 Rotações do alvo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dynamic-embassy",
   "metadata": {},
   "source": [
    "Ref: https://www.geeksforgeeks.org/python-opencv-cv2-rotate-method/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "intensive-seminar",
   "metadata": {},
   "outputs": [],
   "source": [
    "alvo1rot = cv2.rotate(alvo0rot, cv2.ROTATE_90_CLOCKWISE) \n",
    "alvo2rot = cv2.rotate(alvo1rot, cv2.ROTATE_90_CLOCKWISE) \n",
    "alvo3rot = cv2.rotate(alvo2rot, cv2.ROTATE_90_CLOCKWISE) \n",
    "alvos = [alvo0rot, alvo1rot,alvo2rot,alvo3rot]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "descending-assembly",
   "metadata": {},
   "source": [
    "### 2.3 - Extração de bordas e contornos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "assisted-bottle",
   "metadata": {},
   "source": [
    "##### 2.3.1 - Extração de bordas (B&W -> Binarização -> Bordas)\n",
    "Ref: https://docs.opencv.org/master/da/d22/tutorial_py_canny.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "palestinian-burns",
   "metadata": {},
   "outputs": [],
   "source": [
    "def binarize(image):\n",
    "    grayscale = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    _, binarizado = cv2.threshold(grayscale, 127, 255, cv2.THRESH_BINARY)\n",
    "    return binarizado\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unique-clause",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_edges_given_binarized(binarizado):\n",
    "    imageEdges = cv2.Canny(binarizado, 100, 200)\n",
    "    return imageEdges\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "religious-binary",
   "metadata": {},
   "source": [
    "##### 2.3.2 Extração de contornos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mature-leather",
   "metadata": {},
   "source": [
    "Ref: https://opencv-python-tutroals.readthedocs.io/en/latest/py_tutorials/py_imgproc/py_contours/py_contours_begin/py_contours_begin.html#contours-getting-started"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "closed-validation",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_contours_given_edges(imageEdges):\n",
    "    contorno, _  = cv2.findContours(imageEdges, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    return contorno"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "limiting-point",
   "metadata": {},
   "source": [
    "## 2.4 - Identificação de quadrilateros na imagem"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "valued-loading",
   "metadata": {},
   "source": [
    "Ref: https://stackoverflow.com/questions/55169645/square-detection-in-image/\n",
    "Ref2: https://stackoverflow.com/questions/61166180/detect-rectangles-in-opencv-4-2-0-using-python-3-7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "conceptual-detection",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_squares_given_contours(edgesContours):\n",
    "    squares = list()\n",
    "    for contour in edgesContours:\n",
    "        epsilon = 0.05*cv2.arcLength(contour,True)\n",
    "        polygon = cv2.approxPolyDP(contour, epsilon, True)\n",
    "        if len(polygon) == 4 and cv2.isContourConvex(polygon):\n",
    "            squares.append(polygon)\n",
    "    return squares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "complex-graphics",
   "metadata": {},
   "outputs": [],
   "source": [
    "def template_corners_coords(template):\n",
    "    s = template.shape\n",
    "    return np.float32([[0,0], [0, s[0]], [s[1], s[0]], [s[1], 0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "indonesian-manufacturer",
   "metadata": {},
   "outputs": [],
   "source": [
    "def homography_and_matching(corner_coords,quadrados, image):\n",
    "    quadrados_matched = []\n",
    "    orientacao = []\n",
    "    poses_na_cena = []\n",
    "    for q in quadrados: \n",
    "        image_homography, _ = cv2.findHomography(np.float32(q), corner_coords, cv2.RANSAC)\n",
    "        result = cv2.warpPerspective(image, image_homography, alvo0rot.shape)           \n",
    "        \n",
    "        diffs = [0] * len(alvos)\n",
    "\n",
    "        for i,rot in enumerate(alvos):\n",
    "            diffs[i] = np.sum(np.abs(result - rot)) / (result.size)\n",
    "            \n",
    "        #Valor 50 para a diferença absoluta foi escolhido de forma empirica\n",
    "        if min(diffs) <20:\n",
    "            poses_na_cena.append( (q, diffs.index(min(diffs))) )\n",
    "            #quadrados_matched.append(q)\n",
    "            #orientacao.append(diffs.index(min(diffs)))\n",
    "            \n",
    "    return poses_na_cena"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "czech-milan",
   "metadata": {},
   "outputs": [],
   "source": [
    "def homography(corner_coords,quadrados, image):\n",
    "    quadrados_matched = []\n",
    "    orientacao = []\n",
    "    #poses_na_cena = []\n",
    "    for q in quadrados: \n",
    "        image_homography, _ = cv2.findHomography(np.float32(q), corner_coords, cv2.RANSAC)\n",
    "        result = cv2.warpPerspective(image, image_homography, alvo0rot.shape)           \n",
    "        \n",
    "        diffs = [0] * len(alvos)\n",
    "        for i,rot in enumerate(alvos):\n",
    "            diffs[i] = np.sum(np.abs(result - rot)) / (result.size)\n",
    "            \n",
    "        #Valor 50 para a diferença absoluta foi escolhido de forma empirica\n",
    "        if min(diffs) <20 :\n",
    "            #poses_na_cena.append( (q, diffs.index(min(diffs))) )\n",
    "            quadrados_matched.append(q)\n",
    "            orientacao.append(diffs.index(min(diffs)))\n",
    "            \n",
    "    #return (quadrados_matched, orientacao)\n",
    "    return (quadrados_matched, orientacao)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "signed-still",
   "metadata": {},
   "outputs": [],
   "source": [
    "def processa_frames(frames, alvo, mapa_rotacao):\n",
    "    frame_processado = [] # Cada elemento é uma tripla (frame, posicao, orientacao)\n",
    "    for frame in frames:\n",
    "        binarizado = binarize(frame)\n",
    "        edges = extract_edges_given_binarized(binarizado)\n",
    "        contornos = extract_contours_given_edges(edges)\n",
    "\n",
    "        # Aproxima um poligono em cada contorno obtido. Caso tal polígono possua quatro lados e seja\n",
    "        # convexo, então o mesmo é classificado como quadrilatero - que é a mesma classificação dos alvos\n",
    "        # procurados.\n",
    "        lista_quadrilateros = find_squares_given_contours(contornos)\n",
    "    \n",
    "        \n",
    "        \n",
    "        cornerCoords = template_corners_coords(alvo0rot)\n",
    "        \n",
    "    \n",
    "\n",
    "        frame_processado.append(homography_and_matching(cornerCoords, lista_quadrilateros, binarizado))\n",
    "        \n",
    "\n",
    "    return frame_processado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "embedded-luxembourg",
   "metadata": {},
   "outputs": [],
   "source": [
    "cornerCoords = template_corners_coords(alvo0rot)\n",
    "#videoMatches = list()\n",
    "poly = list()\n",
    "#matchesOrientations = list()\n",
    "direction = list()\n",
    "\n",
    "cena = []\n",
    "\n",
    "for frame in frames:\n",
    "    binarizado = binarize(frame)\n",
    "    edges = extract_edges_given_binarized(binarizado)\n",
    "    contorno = extract_contours_given_edges(edges)\n",
    "    squares = find_squares_given_contours(contorno)\n",
    "    temp1,temp2 = homography(cornerCoords,squares, binarizado)\n",
    "    #videoMatches.append(frameMatches)\n",
    "    poly.append(temp1)\n",
    "    direction.append(temp2)\n",
    "    #cena.append(homo)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "animated-appreciation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cornerCoords = template_corners_coords(alvo0rot)\n",
    "# #videoMatches = list()\n",
    "# #poly = list()\n",
    "# #matchesOrientations = list()\n",
    "# #direction = list()\n",
    "\n",
    "# cena = []\n",
    "\n",
    "# for frame in frames:\n",
    "#     binarizado = binarize(frame)\n",
    "#     edges = extract_edges_given_binarized(binarizado)\n",
    "#     contorno = extract_contours_given_edges(edges)\n",
    "#     squares = find_squares_given_contours(contorno)\n",
    "#     homo = homography(cornerCoords,squares, binarizado)\n",
    "#     #videoMatches.append(frameMatches)\n",
    "#     cena.append(homo)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "terminal-relationship",
   "metadata": {},
   "outputs": [],
   "source": [
    "#highlight = cv2.drawContours(frames[120], videoMatches[120], -1, (100,100,255), 3)\n",
    "#plt.imshow(highlight)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "periodic-excitement",
   "metadata": {},
   "source": [
    "# 3. Os parâmetros extrínsecos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stuffed-jones",
   "metadata": {},
   "outputs": [],
   "source": [
    "#poly = [c[0] for c in cena]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "persistent-astronomy",
   "metadata": {},
   "outputs": [],
   "source": [
    "#direction = [c[1] for c in cena]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tough-baghdad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def obtem_pose(polygon, direction):    \n",
    "    #coords = list()   \n",
    "    #coords.append(np.float32([[-1, 1, 0], [-1, -1, 0], [1, -1, 0], [1, 1, 0]])) # 0°\n",
    "    #coords.append(np.float32([[-1, -1, 0], [1, -1, 0], [1, 1, 0], [-1, 1, 0]])) # 90°\n",
    "    #coords.append(np.float32([[1, -1, 0], [1, 1, 0], [-1, 1, 0], [-1, -1, 0]])) # 180°\n",
    "    #coords.append(np.float32([[1, 1, 0], [-1, 1, 0], [-1, -1, 0], [1, -1, 0]]))\n",
    "    \n",
    "    if direction == 0:\n",
    "        dst = np.float32([[-1, 1, 0], [-1, -1, 0], [1, -1, 0], [1, 1, 0]])\n",
    "    if direction == 1:\n",
    "        dst = np.float32([[-1, -1, 0], [1, -1, 0], [1, 1, 0], [-1, 1, 0]])\n",
    "    if direction == 2:\n",
    "        dst = np.float32([[1, -1, 0], [1, 1, 0], [-1, 1, 0], [-1, -1, 0]])     \n",
    "    if direction == 3:\n",
    "        dst = np.float32([[1, 1, 0], [-1, 1, 0], [-1, -1, 0], [1, -1, 0]])\n",
    "\n",
    "    _, rot, trans = cv2.solvePnP(dst, np.float32(polygon), intrinsicMatrix, np.float32(cameraDistortion))\n",
    "    rodRot, _ = cv2.Rodrigues(rot)\n",
    "    \n",
    "    \n",
    "    matriz_pose = np.append(rodRot, trans, axis=1)\n",
    "    #lastRow = [0,0,0,1]\n",
    "    matriz_pose = np.append(matriz_pose, [[0,0,0,1]], axis = 0)\n",
    "    \n",
    "       \n",
    "    matriz_pose[1, 0] =  matriz_pose[1, 0] * -1\n",
    "    matriz_pose[2, 0] = matriz_pose[2, 0] * -1 \n",
    "    matriz_pose[1, 1] = matriz_pose[1, 1] * -1\n",
    "    matriz_pose[2, 1] = matriz_pose[2, 1] * -1\n",
    "    matriz_pose[1, 2] = matriz_pose[1, 2] * -1\n",
    "    matriz_pose[2, 2] = matriz_pose[2, 2] * -1\n",
    "    matriz_pose[1, 3] = matriz_pose[1, 3] * -1\n",
    "    matriz_pose[2, 3] = matriz_pose[2, 3] * -1\n",
    "    \n",
    "    return np.transpose(matriz_pose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "precious-drove",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para definir ajustes intrínsecos da câmera\n",
    "def ajuste_intrinsecos_camera(width, height, K):\n",
    "    fx = K[0, 0]\n",
    "    fy = K[1, 1]\n",
    "    fovy = 2 * np.arctan(0.5 * height / fy) * 180 / np.pi\n",
    "    aspect = width * fy / (height * fx)\n",
    "    gluPerspective(fovy, aspect, 0.1, 100.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "closing-output",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função de renderização dos cubos\n",
    "def render_cube():\n",
    "    glPushAttrib(GL_CURRENT_BIT)\n",
    "    glColor3f(100/255,100/255,1)\n",
    "    glLineWidth(3.0)\n",
    "    glTranslate(0, 0, 1)\n",
    "    glutWireCube(2.0)\n",
    "\n",
    "    glLineWidth(4.0)\n",
    "    glColor3f(1,100/255,100/255)\n",
    "    glBegin(GL_LINES)\n",
    "    glVertex3f(-1, 1, -0.9)\n",
    "    glVertex3f(1, 1, -0.9)\n",
    "    glEnd()\n",
    "\n",
    "    glPopAttrib()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "valuable-beast",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Renderizando cubos e pikachu\n",
    "def render():\n",
    "    global render_pikachu\n",
    "    global render_cubes\n",
    "    for p, d in zip(poly[current_frame], direction[current_frame]):\n",
    "        m_mat = obtem_pose(p, d)\n",
    "        glLoadMatrixf(m_mat)\n",
    "        \n",
    "        if render_cubes:\n",
    "            render_cube()    \n",
    "        if render_pikachu:\n",
    "            glCallList(pikachu.gl_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "micro-working",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iniciando o OpenGL\n",
    "def init_open_gl():\n",
    "    glClearColor(0, 0, 0, 0)\n",
    "    glClearDepth(1.0)\n",
    "    glEnable(GL_DEPTH_TEST)\n",
    "    glMatrixMode(GL_PROJECTION)\n",
    "    glLoadIdentity()\n",
    "    ajuste_intrinsecos_camera(640, 480, intrinsicMatrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "honest-bundle",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gerando o background\n",
    "def background(img):\n",
    "    bitmap_tex = glGenTextures(1)\n",
    "    glBindTexture(GL_TEXTURE_2D, bitmap_tex)\n",
    "    glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_MIN_FILTER, GL_NEAREST)\n",
    "    glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_MAG_FILTER, GL_NEAREST)\n",
    "    \n",
    "    glTexImage2D(GL_TEXTURE_2D, 0, GL_RGB, 640, 480, 0, GL_BGR, GL_UNSIGNED_BYTE, img)\n",
    "\n",
    "    glDepthMask(GL_FALSE)\n",
    "    glMatrixMode(GL_PROJECTION)\n",
    "    glLoadIdentity()\n",
    "    glOrtho(0, 640, 480, 0.0, 0.0, 1)\n",
    "    \n",
    "    glEnable( GL_TEXTURE_2D )\n",
    "    glBegin(GL_QUADS)\n",
    "    glTexCoord2f(0, 0);\n",
    "    glVertex2f(0, 0);\n",
    "    glTexCoord2f(1, 0);\n",
    "    glVertex2f(640, 0);\n",
    "    glTexCoord2f(1, 1);\n",
    "    glVertex2f(640, 480);\n",
    "    glTexCoord2f(0, 1);\n",
    "    glVertex2f(0, 480);\n",
    "    glEnd()\n",
    "\n",
    "    glBindTexture(GL_TEXTURE_2D, 0)\n",
    "    glDepthMask(GL_TRUE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "classical-academy",
   "metadata": {},
   "outputs": [],
   "source": [
    "current_frame = 0\n",
    "\n",
    "def display_callback(pikachu):\n",
    "    global current_frame\n",
    "\n",
    "    glMatrixMode(GL_MODELVIEW)\n",
    "    glLoadIdentity()\n",
    "    glClear(GL_COLOR_BUFFER_BIT | GL_DEPTH_BUFFER_BIT)\n",
    "\n",
    "    background(frames[current_frame])\n",
    "    current_frame = (current_frame + 1) % len(poly)\n",
    "\n",
    "    glMatrixMode(GL_PROJECTION)\n",
    "    glLoadIdentity() \n",
    "    ajuste_intrinsecos_camera(640, 480, intrinsicMatrix)\n",
    "\n",
    "    glMatrixMode(GL_MODELVIEW)\n",
    "    glLoadIdentity()\n",
    "    glEnable(GL_TEXTURE_2D)\n",
    "\n",
    "    render()\n",
    "    \n",
    "    glutSwapBuffers()\n",
    "    time.sleep(1 / 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "northern-density",
   "metadata": {},
   "outputs": [],
   "source": [
    "dimensoes = (640, 480)\n",
    "glutInit()\n",
    "glutInitDisplayMode(GLUT_RGBA | GLUT_DOUBLE)\n",
    "glutSetOption(GLUT_ACTION_ON_WINDOW_CLOSE, GLUT_ACTION_CONTINUE_EXECUTION)\n",
    "glutInitWindowSize(*dimensoes)\n",
    "glutCreateWindow(b'TP 2')\n",
    "\n",
    "init_open_gl()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "desperate-hawaiian",
   "metadata": {},
   "outputs": [],
   "source": [
    "pikachu = OBJ('Pikachu.obj', swapyz=True)\n",
    "display = lambda : display_callback(pikachu)\n",
    "glutDisplayFunc(display)\n",
    "glutIdleFunc(glutPostRedisplay)\n",
    "\n",
    "glutMainLoop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "paperback-mongolia",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "equipped-vocabulary",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "opening-championship",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nervous-advertiser",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "continuous-rendering",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "willing-penalty",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "laughing-immunology",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "downtown-melissa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "close-attitude",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "attempted-weekly",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "professional-indie",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "separate-boundary",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "numerical-jacksonville",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "scheduled-worker",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "multiple-tennis",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fuzzy-element",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "partial-driving",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sought-television",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "decimal-vatican",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alpha-cabinet",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "equivalent-repair",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "contained-growth",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cloudy-expense",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cellular-bloom",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "subsequent-monitor",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wireless-royal",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "threaded-insert",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "supported-stupid",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "spare-conflict",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "taken-fountain",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "interior-outreach",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "smooth-tulsa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bright-avatar",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "residential-harmony",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "civic-villa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "substantial-insertion",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "racial-scotland",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "composite-orchestra",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para definir ajustes intrínsecos da câmera\n",
    "def ajuste_intrinsecos_camera(width, height, K):\n",
    "    fx = K[0, 0]\n",
    "    fy = K[1, 1]\n",
    "    fovy = 2 * np.arctan(0.5 * height / fy) * 180 / np.pi\n",
    "    aspect = width * fy / (height * fx)\n",
    "    gluPerspective(fovy, aspect, 0.1, 100.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "suburban-divorce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função de renderização dos cubos\n",
    "def render_cube():\n",
    "    glPushAttrib(GL_CURRENT_BIT)\n",
    "    glColor3f(100/255,100/255,1)\n",
    "    glLineWidth(3.0)\n",
    "    glTranslate(0, 0, 1)\n",
    "    glutWireCube(2.0)\n",
    "\n",
    "    glLineWidth(4.0)\n",
    "    glColor3f(1,100/255,100/255)\n",
    "    glBegin(GL_LINES)\n",
    "    glVertex3f(-1, 1, -0.9)\n",
    "    glVertex3f(1, 1, -0.9)\n",
    "    glEnd()\n",
    "\n",
    "    glPopAttrib()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "polished-monitor",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Renderizando cubos e pikachu\n",
    "def render():\n",
    "    coords = list()   \n",
    "    coords.append(np.float32([[-1, 1, 0], [-1, -1, 0], [1, -1, 0], [1, 1, 0]])) # 0°\n",
    "    coords.append(np.float32([[-1, -1, 0], [1, -1, 0], [1, 1, 0], [-1, 1, 0]])) # 90°\n",
    "    coords.append(np.float32([[1, -1, 0], [1, 1, 0], [-1, 1, 0], [-1, -1, 0]])) # 180°\n",
    "    coords.append(np.float32([[1, 1, 0], [-1, 1, 0], [-1, -1, 0], [1, -1, 0]]))\n",
    "    global render_pikachu\n",
    "    global render_cubes\n",
    "    for p, d in zip(videoMatches[current_frame], matchesOrientations[current_frame]):\n",
    "        m_mat = obtem_pose(p, d)\n",
    "        glLoadMatrixf(m_mat)\n",
    "        \n",
    "        if render_cubes:\n",
    "            render_cube()    \n",
    "        if render_pikachu:\n",
    "            glCallList(pikachu.gl_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "freelance-flour",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iniciando o OpenGL\n",
    "def init_open_gl():\n",
    "    glClearColor(0, 0, 0, 0)\n",
    "    glClearDepth(1.0)\n",
    "    glEnable(GL_DEPTH_TEST)\n",
    "    glMatrixMode(GL_PROJECTION)\n",
    "    glLoadIdentity()\n",
    "    ajuste_intrinsecos_camera(640, 480, intrinsicMatrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unavailable-lodge",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gerando o background\n",
    "def background(img):\n",
    "    bitmap_tex = glGenTextures(1)\n",
    "    glBindTexture(GL_TEXTURE_2D, bitmap_tex)\n",
    "    glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_MIN_FILTER, GL_NEAREST)\n",
    "    glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_MAG_FILTER, GL_NEAREST)\n",
    "    \n",
    "    glTexImage2D(GL_TEXTURE_2D, 0, GL_RGB, 640, 480, 0, GL_BGR, GL_UNSIGNED_BYTE, img)\n",
    "\n",
    "    glDepthMask(GL_FALSE)\n",
    "    glMatrixMode(GL_PROJECTION)\n",
    "    glLoadIdentity()\n",
    "    glOrtho(0, 640, 480, 0.0, 0.0, 1)\n",
    "    \n",
    "    glEnable( GL_TEXTURE_2D )\n",
    "    glBegin(GL_QUADS)\n",
    "    glTexCoord2f(0, 0);\n",
    "    glVertex2f(0, 0);\n",
    "    glTexCoord2f(1, 0);\n",
    "    glVertex2f(640, 0);\n",
    "    glTexCoord2f(1, 1);\n",
    "    glVertex2f(640, 480);\n",
    "    glTexCoord2f(0, 1);\n",
    "    glVertex2f(0, 480);\n",
    "    glEnd()\n",
    "\n",
    "    glBindTexture(GL_TEXTURE_2D, 0)\n",
    "    glDepthMask(GL_TRUE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "american-symbol",
   "metadata": {},
   "outputs": [],
   "source": [
    "current_frame = 0\n",
    "\n",
    "def display_callback(pikachu):\n",
    "    global current_frame\n",
    "\n",
    "    glMatrixMode(GL_MODELVIEW)\n",
    "    glLoadIdentity()\n",
    "    glClear(GL_COLOR_BUFFER_BIT | GL_DEPTH_BUFFER_BIT)\n",
    "\n",
    "    background(frames[current_frame])\n",
    "    current_frame = (current_frame + 1) % len(videoMatches)\n",
    "\n",
    "    glMatrixMode(GL_PROJECTION)\n",
    "    glLoadIdentity() \n",
    "    ajuste_intrinsecos_camera(640, 480, intrinsicMatrix)\n",
    "\n",
    "    glMatrixMode(GL_MODELVIEW)\n",
    "    glLoadIdentity()\n",
    "    glEnable(GL_TEXTURE_2D)\n",
    "\n",
    "    #render()\n",
    "    \n",
    "    glutSwapBuffers()\n",
    "    time.sleep(1 / 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "distant-invention",
   "metadata": {},
   "outputs": [],
   "source": [
    "dimensoes = (640, 480)\n",
    "glutInit()\n",
    "glutInitDisplayMode(GLUT_RGBA | GLUT_DOUBLE)\n",
    "glutSetOption(GLUT_ACTION_ON_WINDOW_CLOSE, GLUT_ACTION_CONTINUE_EXECUTION)\n",
    "glutInitWindowSize(*dimensoes)\n",
    "glutCreateWindow(b'TP 2')\n",
    "\n",
    "init_open_gl()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exact-reputation",
   "metadata": {},
   "outputs": [],
   "source": [
    "pikachu = OBJ('Pikachu.obj', swapyz=True)\n",
    "display = lambda : display_callback(pikachu)\n",
    "glutDisplayFunc(display)\n",
    "glutIdleFunc(glutPostRedisplay)\n",
    "\n",
    "glutMainLoop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bacterial-extension",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "changed-visit",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "advance-external",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "controlled-boxing",
   "metadata": {},
   "outputs": [],
   "source": [
    "#OOLLDDDDD functional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "armed-purple",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initOpenGL(dimensions):\n",
    "    width, height = dimensions\n",
    "\n",
    "    gl.glClearColor(0.0, 0.0, 0.0, 0.0)\n",
    "    gl.glClearDepth(1.0)\n",
    "\n",
    "    gl.glEnable(gl.GL_DEPTH_TEST)\n",
    "\n",
    "    gl.glMatrixMode(gl.GL_PROJECTION)\n",
    "    gl.glLoadIdentity()\n",
    "    \n",
    "    \n",
    "    fx = intrinsicMatrix[0, 0]\n",
    "    fy = intrinsicMatrix[1, 1]\n",
    "    fovy = 2*np.arctan(0.5*height/fy) * 180/np.pi\n",
    "    aspect = (width*fy)/(height*fx)\n",
    "\n",
    "    near = 0.1\n",
    "    far = 100.0\n",
    "\n",
    "    glu.gluPerspective(fovy, aspect, near, far)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "speaking-casino",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_view(width, height, K):\n",
    "    gl.glViewport(0, 0, width, height)\n",
    "\n",
    "    gl.glMatrixMode(gl.GL_PROJECTION)\n",
    "    gl.glLoadIdentity()\n",
    "    \n",
    "    fx = K[0, 0]\n",
    "    fy = K[1, 1]\n",
    "    fovy = 2*np.arctan(0.5*height/fy) * 180/np.pi\n",
    "    aspect = (width*fy)/(height*fx)\n",
    "    near = 0.1\n",
    "    far = 100.0\n",
    "    glu.gluPerspective(fovy, aspect, near, far)\n",
    "    \n",
    "\n",
    "    gl.glMatrixMode(gl.GL_MODELVIEW)\n",
    "    gl.glLoadIdentity()\n",
    "    glu.gluLookAt(0, 0, 5, 0, 0, 0, 0, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "simple-tiger",
   "metadata": {},
   "outputs": [],
   "source": [
    "def background(img):\n",
    "    id_textura = gl.glGenTextures(1)\n",
    "    gl.glBindTexture(gl.GL_TEXTURE_2D, id_textura)\n",
    "\n",
    "    fundo = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    #fundo = cv2.flip(fundo, 0)\n",
    "    \n",
    "    gl.glTexParameteri(gl.GL_TEXTURE_2D, gl.GL_TEXTURE_MAG_FILTER, gl.GL_LINEAR)\n",
    "    gl.glTexParameteri(gl.GL_TEXTURE_2D, gl.GL_TEXTURE_MIN_FILTER, gl.GL_LINEAR)\n",
    "    gl.glTexImage2D(gl.GL_TEXTURE_2D, 0, gl.GL_RGB, 640, 480, 0, gl.GL_RGB, gl.GL_UNSIGNED_BYTE, fundo)\n",
    "\n",
    "    gl.glDepthMask(gl.GL_FALSE)\n",
    "    gl.glDisable( gl.GL_DEPTH_TEST )\n",
    "\n",
    "    gl.glMatrixMode(gl.GL_PROJECTION)\n",
    "    gl.glLoadIdentity()\n",
    "    gl.glOrtho(0, 640, 480, 0.0, 0.0, 1)\n",
    "    \n",
    "    gl.glEnable( gl.GL_TEXTURE_2D )\n",
    "    gl.glBegin(gl.GL_QUADS)\n",
    "    gl.glTexCoord2f(0, 0); gl.glVertex2f(0, 0)\n",
    "    gl.glTexCoord2f(1, 0); gl.glVertex2f(640, 0)\n",
    "    gl.glTexCoord2f(1, 1); gl.glVertex2f(640, 480)\n",
    "    gl.glTexCoord2f(0, 1); gl.glVertex2f(0, 480)\n",
    "    gl.glEnd()\n",
    "\n",
    "    gl.glBindTexture(gl.GL_TEXTURE_2D, 0)\n",
    "    gl.glEnable( gl.GL_DEPTH_TEST )\n",
    "    gl.glDepthMask(gl.GL_TRUE)\n",
    "\n",
    "    gl.glFlush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "saving-privacy",
   "metadata": {},
   "outputs": [],
   "source": [
    "def desenha_pikachus_nas_posicoes(obj, infos_cena_atual):\n",
    "    for posicao, orientacao in infos_cena_atual:   \n",
    "        m = obtem_pose(posicao, orientacao)\n",
    "        gl.glLoadMatrixf(m)\n",
    "        gl.glCallList(obj.gl_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "liable-gates",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cria_e_posiciona_cubo(m):\n",
    "\n",
    "    vertices = (\n",
    "        (1, -1, -1), (1, 1, -1), (-1, 1, -1),\n",
    "        (-1, -1, -1),(1, -1, 1), (1, 1, 1),\n",
    "        (-1, -1, 1), (-1, 1, 1)\n",
    "    )\n",
    "\n",
    "    arestas = (\n",
    "        (2,1), (0,1), (0,3),\n",
    "        (0,4), (2,3), (2,7),\n",
    "        (6,3), (6,4), (6,7),\n",
    "        (5,1), (5,4), (5,7)\n",
    "    )\n",
    "    \n",
    "    gl.glMatrixMode(gl.GL_MODELVIEW)\n",
    "    gl.glLoadIdentity()\n",
    "    gl.glLoadMatrixf(m)\n",
    "\n",
    "    gl.glPushAttrib(gl.GL_CURRENT_BIT)\n",
    "    gl.glLineWidth(4)\n",
    "\n",
    "    gl.glBegin(gl.GL_LINES)\n",
    "    gl.glColor3f(124/255, 252/255, 0)\n",
    "    first_seg = True\n",
    "    for aresta in arestas:\n",
    "        for vertice in aresta:\n",
    "            gl.glVertex3fv(vertices[vertice])\n",
    "            if first_seg:\n",
    "                first_seg = False\n",
    "                gl.glColor3f(124/255, 252/255, 0)\n",
    "            else:\n",
    "                gl.glColor3f(230/255, 0., 126/255)\n",
    "    gl.glEnd()\n",
    "\n",
    "    gl.glMatrixMode(gl.GL_PROJECTION)\n",
    "    gl.glLoadIdentity()\n",
    "    gl.glPopAttrib()\n",
    "    gl.glFlush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "municipal-species",
   "metadata": {},
   "outputs": [],
   "source": [
    "def desenha_cubos_nas_posicoes(infos_cena_atual):\n",
    "    for posicao, orientacao in infos_cena_atual:   \n",
    "        m = obtem_pose(posicao, orientacao)\n",
    "        cria_e_posiciona_cubo(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "expensive-wonder",
   "metadata": {},
   "outputs": [],
   "source": [
    "def renderiza_pikachus(infos_cena_atual, modelo_objeto):    \n",
    "    gl.glMatrixMode(gl.GL_MODELVIEW)\n",
    "    gl.glLoadIdentity()\n",
    "    gl.glEnable(gl.GL_TEXTURE_2D)\n",
    "\n",
    "    desenha_pikachus_nas_posicoes(modelo_objeto, infos_cena_atual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bibliographic-dallas",
   "metadata": {},
   "outputs": [],
   "source": [
    "def renderiza_cubos(infos_cena_atual):    \n",
    "    gl.glMatrixMode(gl.GL_MODELVIEW)\n",
    "    gl.glLoadIdentity()\n",
    "    gl.glEnable(gl.GL_TEXTURE_2D)\n",
    "\n",
    "    desenha_cubos_nas_posicoes(infos_cena_atual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "million-principal",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cria_cena(frames, frames_processados, modelo_pikachu):\n",
    "    global frame_index\n",
    "    global render_cubo\n",
    "    global render_pikachu\n",
    "\n",
    "    if frame_index >= len(frames_processados) and not render_pikachu:\n",
    "        render_pikachu = True\n",
    "        render_cubo = False\n",
    "        frame_index = 0\n",
    "\n",
    "    elif frame_index >= len(frames_processados) and render_pikachu:\n",
    "        return\n",
    "\n",
    "    gl.glMatrixMode(gl.GL_MODELVIEW)\n",
    "    gl.glLoadIdentity()\n",
    "    gl.glClear(gl.GL_COLOR_BUFFER_BIT | gl.GL_DEPTH_BUFFER_BIT)\n",
    "\n",
    "    infos_cena_atual = frames_processados[frame_index]\n",
    "\n",
    "    background(frames[frame_index])\n",
    "    gl.glMatrixMode(gl.GL_PROJECTION)\n",
    "    gl.glLoadIdentity() \n",
    "    K = intrinsicMatrix\n",
    "    \n",
    "    \n",
    "    \n",
    "    fx = K[0, 0]\n",
    "    fy = K[1, 1]\n",
    "\n",
    "    fovy = 2*np.arctan(0.5*480/fy) * 180/np.pi\n",
    "    aspect = (640*fy)/(480*fx)\n",
    "\n",
    "    near = 0.1\n",
    "    far = 100.0\n",
    "\n",
    "    glu.gluPerspective(fovy, aspect, near, far)\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "    if render_pikachu:\n",
    "        renderiza_pikachus(infos_cena_atual, modelo_pikachu)\n",
    "    else:\n",
    "        renderiza_cubos(infos_cena_atual)\n",
    "\n",
    "    glut.glutSwapBuffers()\n",
    "\n",
    "    time.sleep(1/18) # Valor qualquer pro vídeo nao ficar muito rapido\n",
    "    frame_index = frame_index + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "latin-curtis",
   "metadata": {},
   "outputs": [],
   "source": [
    "def idleCallback():\n",
    "    glut.glutPostRedisplay()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cellular-minneapolis",
   "metadata": {},
   "outputs": [],
   "source": [
    "def realidade_aumentada_pikachu(frames, frames_processados):\n",
    "    dimensoes_frame = (640, 480)\n",
    "\n",
    "    K = intrinsicMatrix\n",
    "\n",
    "    glut.glutInit()\n",
    "    glut.glutInitDisplayMode(glut.GLUT_RGBA | glut.GLUT_DOUBLE)\n",
    "    glut.glutSetOption(glut.GLUT_ACTION_ON_WINDOW_CLOSE, glut.GLUT_ACTION_CONTINUE_EXECUTION)\n",
    "    glut.glutInitWindowSize(*dimensoes_frame)\n",
    "    janela = glut.glutCreateWindow(b'Realidade Aumentada - Pikachu')\n",
    "    \n",
    "    initOpenGL(dimensoes_frame)\n",
    "\n",
    "    global frame_index\n",
    "    frame_index = 0\n",
    "\n",
    "    global render_pikachu\n",
    "    render_pikachu = False\n",
    "\n",
    "    global render_cubo\n",
    "    render_cubo = True\n",
    "\n",
    "    obj = OBJ(\"Pikachu.obj\", swapyz=True)\n",
    "    \n",
    "    display_callback = lambda: cria_cena(frames, frames_processados, obj)\n",
    "    reshape_callback = lambda w, h: resize_view(w, h, K)\n",
    "\n",
    "    glut.glutDisplayFunc(display_callback)\n",
    "    glut.glutReshapeFunc(reshape_callback)\n",
    "    glut.glutIdleFunc(idleCallback)\n",
    "    glut.glutMainLoop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "threatened-martial",
   "metadata": {},
   "outputs": [],
   "source": [
    "#testando =(videoMatches,matchesOrientations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "whole-sherman",
   "metadata": {},
   "outputs": [],
   "source": [
    "#testando = [[a]  for a in zip(videoMatches,matchesOrientations)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "combined-standard",
   "metadata": {},
   "outputs": [],
   "source": [
    "#testando"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "moderate-product",
   "metadata": {},
   "outputs": [],
   "source": [
    "#zip(videoMatches,matchesOrientations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pediatric-living",
   "metadata": {},
   "outputs": [],
   "source": [
    "alvo, cantos_alvo = alvo0rot, template_corners_coords(alvo0rot)\n",
    "\n",
    "mapa_rotacao = {}\n",
    "mapa_rotacao[0] = alvo0rot\n",
    "mapa_rotacao[90] = alvo1rot\n",
    "mapa_rotacao[180] = alvo2rot\n",
    "mapa_rotacao[270] = alvo3rot\n",
    "\n",
    "mapa_coordenada = {}\n",
    "mapa_coordenada[90] = np.float32([[-1, 1, 0], [-1, -1, 0], [1, -1, 0], [1, 1, 0]])\n",
    "mapa_coordenada[0] = np.float32([[-1, -1, 0], [1, -1, 0], [1, 1, 0], [-1, 1, 0]])\n",
    "mapa_coordenada[270] = np.float32([[1, -1, 0], [1, 1, 0], [-1, 1, 0], [-1, -1, 0]])\n",
    "mapa_coordenada[180] = np.float32([[1, 1, 0], [-1, 1, 0], [-1, -1, 0], [1, -1, 0]])\n",
    "\n",
    "\n",
    "\n",
    "frames_processados = processa_frames(frames, alvo, mapa_rotacao)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prime-digest",
   "metadata": {},
   "outputs": [],
   "source": [
    "frames_processados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tropical-camcorder",
   "metadata": {},
   "outputs": [],
   "source": [
    "realidade_aumentada_pikachu(frames, frames_processados)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceramic-drawing",
   "metadata": {},
   "outputs": [],
   "source": [
    "alvo, cantos_alvo = obtem_alvo()\n",
    "frames = captura_frames()\n",
    "mapa_rotacao, mapa_coordenada = gera_mapa_rotacoes_alvo(alvo)\n",
    "frames_processados = processa_frames(frames, alvo, mapa_rotacao)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "average-silence",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "worldwide-harmony",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "powered-dollar",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "round-generic",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "satisfied-quarterly",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "functional-vocabulary",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "above-short",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "coral-powder",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dutch-enlargement",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "minimal-revolution",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "frank-bones",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "speaking-confirmation",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "loose-coordinator",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "clinical-piece",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initOpenGL(dimensions):\n",
    "\n",
    "    (width, height) = dimensions\n",
    "    \n",
    "    glClearColor(0.0, 0.0, 0.0, 0.0)\n",
    "    glClearDepth(1.0)\n",
    "\n",
    "    glEnable(GL_DEPTH_TEST)\n",
    "\n",
    "    glMatrixMode(GL_PROJECTION)\n",
    "    glLoadIdentity()\n",
    " \n",
    "    fovy = 45\n",
    "    aspect = (width)/(height)\n",
    "    gluPerspective(fovy, aspect, 0.1, 100.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stone-fetish",
   "metadata": {},
   "outputs": [],
   "source": [
    "def object3D(obj):\n",
    "\n",
    "    # translada o objeto para ficar 10 unidades distante da camera (para podermos ver o objeto)\n",
    "    glTranslate(0,0,-10)\n",
    "\n",
    "    # move o model em y para centralizar ele\n",
    "    glTranslate(0,-2,0)\n",
    "    # rotaciona o modelo para podermos ve-lo de frente\n",
    "    glRotate(90,1,0,0)\n",
    "    glRotate(180,0,1,0)\n",
    "    # renderiza o modelo do Pikachu\n",
    "    glCallList(obj.gl_list)\n",
    "\n",
    "    # renderiza um cubo\n",
    "    # glutWireCube(2.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "contemporary-broadway",
   "metadata": {},
   "outputs": [],
   "source": [
    "def displayCallback():\n",
    "\n",
    "    glMatrixMode(GL_MODELVIEW)\n",
    "    glLoadIdentity()\n",
    "    \n",
    "    glClear(GL_COLOR_BUFFER_BIT | GL_DEPTH_BUFFER_BIT)\n",
    "    \n",
    "    # carregar o modelo 3D do Pikachu\n",
    "    obj = OBJ(\"Pikachu.obj\", swapyz=True)\n",
    "\n",
    "    # habilita o uso de texturas (o Pikachu tem textura)\n",
    "    glEnable(GL_TEXTURE_2D)\n",
    "\n",
    "    object3D(obj) \n",
    "        \n",
    "    glutSwapBuffers() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "reverse-broad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def idleCallback():\n",
    "\n",
    "    glutPostRedisplay()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "threatened-formation",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    \n",
    "    dimensions = (640, 480)\n",
    "    glutInit()\n",
    "    glutInitDisplayMode(GLUT_RGBA | GLUT_DOUBLE)\n",
    "    glutSetOption(GLUT_ACTION_ON_WINDOW_CLOSE, GLUT_ACTION_CONTINUE_EXECUTION)\n",
    "    glutInitWindowSize(*dimensions)\n",
    "    window = glutCreateWindow(b'Realidade Aumentada [codigo esqueleto]')\n",
    "    \n",
    "    initOpenGL(dimensions)\n",
    "    \n",
    "    glutDisplayFunc(displayCallback)\n",
    "    glutIdleFunc(idleCallback)\n",
    "    \n",
    "    glutMainLoop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "upper-cache",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
